{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomli\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import math\n",
    "import csv\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.toml\", \"rb\") as f:\n",
    "    config = tomli.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>mode</th>\n",
       "      <th>gender</th>\n",
       "      <th>hold racket handed</th>\n",
       "      <th>play years</th>\n",
       "      <th>level</th>\n",
       "      <th>cut_point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[   0   61  122  183  244  305  366  428  489 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[   0   74  149  224  299  374  449  524  599 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[   0  103  207  311  415  519  623  727  831 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[   0  101  203  304  406  507  609  710  812 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[   0  105  211  317  423  529  635  740  846 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id  player_id  mode  gender  hold racket handed  play years  level  \\\n",
       "0          1         41     1       1                   1           1      5   \n",
       "1          2         41     2       1                   1           1      5   \n",
       "2          3         41     3       1                   1           1      5   \n",
       "3          4         41     4       1                   1           1      5   \n",
       "4          5         41     5       1                   1           1      5   \n",
       "\n",
       "                                           cut_point  \n",
       "0  [   0   61  122  183  244  305  366  428  489 ...  \n",
       "1  [   0   74  149  224  299  374  449  524  599 ...  \n",
       "2  [   0  103  207  311  415  519  623  727  831 ...  \n",
       "3  [   0  101  203  304  406  507  609  710  812 ...  \n",
       "4  [   0  105  211  317  423  529  635  740  846 ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_info = pd.read_csv(config['Train']['InfoFile'])\n",
    "train_info.head()\n",
    "# train_info['level'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_players = train_info['player_id'].unique()\n",
    "train_players, test_players = train_test_split(unique_players, test_size=0.2, random_state=42)\n",
    "\n",
    "# 讀取特徵 CSV 檔（位於 \"./tabular_data_train\"）\n",
    "datapath = './tabular_data_train'\n",
    "datalist = glob.glob(os.path.join(config['Train']['FeaturePath'], \"*.csv\"))\n",
    "target_mask = ['gender', 'hold racket handed', 'play years', 'level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ax_mean</th>\n",
       "      <th>ay_mean</th>\n",
       "      <th>az_mean</th>\n",
       "      <th>gx_mean</th>\n",
       "      <th>gy_mean</th>\n",
       "      <th>gz_mean</th>\n",
       "      <th>ax_var</th>\n",
       "      <th>ay_var</th>\n",
       "      <th>az_var</th>\n",
       "      <th>gx_var</th>\n",
       "      <th>...</th>\n",
       "      <th>a_fft</th>\n",
       "      <th>g_fft</th>\n",
       "      <th>a_psd</th>\n",
       "      <th>g_psd</th>\n",
       "      <th>a_kurt</th>\n",
       "      <th>g_kurt</th>\n",
       "      <th>a_skewn</th>\n",
       "      <th>g_skewn</th>\n",
       "      <th>a_entropy</th>\n",
       "      <th>g_entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3210.325581</td>\n",
       "      <td>-1472.639535</td>\n",
       "      <td>769.174419</td>\n",
       "      <td>3888.139535</td>\n",
       "      <td>15000.069767</td>\n",
       "      <td>-1508.011628</td>\n",
       "      <td>2625.734377</td>\n",
       "      <td>2141.530712</td>\n",
       "      <td>2579.672441</td>\n",
       "      <td>22376.099388</td>\n",
       "      <td>...</td>\n",
       "      <td>34235.187587</td>\n",
       "      <td>34235.187587</td>\n",
       "      <td>8.524912e+09</td>\n",
       "      <td>8.524912e+09</td>\n",
       "      <td>7.929079</td>\n",
       "      <td>2.715360</td>\n",
       "      <td>193.153135</td>\n",
       "      <td>63.072307</td>\n",
       "      <td>-0.055732</td>\n",
       "      <td>-0.055732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4266.151163</td>\n",
       "      <td>-1758.790698</td>\n",
       "      <td>433.104651</td>\n",
       "      <td>4868.604651</td>\n",
       "      <td>14022.290698</td>\n",
       "      <td>3694.767442</td>\n",
       "      <td>2716.650412</td>\n",
       "      <td>3104.921440</td>\n",
       "      <td>2033.799252</td>\n",
       "      <td>23827.776754</td>\n",
       "      <td>...</td>\n",
       "      <td>4200.628815</td>\n",
       "      <td>4200.628815</td>\n",
       "      <td>2.855087e+08</td>\n",
       "      <td>2.855087e+08</td>\n",
       "      <td>4.805886</td>\n",
       "      <td>3.387055</td>\n",
       "      <td>116.344046</td>\n",
       "      <td>86.140297</td>\n",
       "      <td>-0.055453</td>\n",
       "      <td>-0.055453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3777.058140</td>\n",
       "      <td>-2363.441860</td>\n",
       "      <td>496.430233</td>\n",
       "      <td>3838.127907</td>\n",
       "      <td>17846.848837</td>\n",
       "      <td>2016.662791</td>\n",
       "      <td>2646.756001</td>\n",
       "      <td>2342.910897</td>\n",
       "      <td>2150.277547</td>\n",
       "      <td>25096.946277</td>\n",
       "      <td>...</td>\n",
       "      <td>8077.753674</td>\n",
       "      <td>8077.753674</td>\n",
       "      <td>2.063152e+08</td>\n",
       "      <td>2.063152e+08</td>\n",
       "      <td>3.828190</td>\n",
       "      <td>2.898664</td>\n",
       "      <td>113.018318</td>\n",
       "      <td>54.248883</td>\n",
       "      <td>-0.056366</td>\n",
       "      <td>-0.056366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3545.058140</td>\n",
       "      <td>-1156.709302</td>\n",
       "      <td>618.046512</td>\n",
       "      <td>3811.674419</td>\n",
       "      <td>14340.662791</td>\n",
       "      <td>3557.930233</td>\n",
       "      <td>2507.900301</td>\n",
       "      <td>2258.403467</td>\n",
       "      <td>1908.365970</td>\n",
       "      <td>22559.762748</td>\n",
       "      <td>...</td>\n",
       "      <td>5265.867665</td>\n",
       "      <td>5265.867665</td>\n",
       "      <td>1.557855e+08</td>\n",
       "      <td>1.557855e+08</td>\n",
       "      <td>2.039432</td>\n",
       "      <td>3.110605</td>\n",
       "      <td>30.070979</td>\n",
       "      <td>67.902479</td>\n",
       "      <td>-0.056986</td>\n",
       "      <td>-0.056986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3078.068966</td>\n",
       "      <td>-793.758621</td>\n",
       "      <td>137.551724</td>\n",
       "      <td>10518.264368</td>\n",
       "      <td>9810.137931</td>\n",
       "      <td>-9929.160920</td>\n",
       "      <td>2518.215706</td>\n",
       "      <td>2126.238452</td>\n",
       "      <td>1811.472957</td>\n",
       "      <td>19047.955661</td>\n",
       "      <td>...</td>\n",
       "      <td>1315.209915</td>\n",
       "      <td>1315.209915</td>\n",
       "      <td>6.176466e+07</td>\n",
       "      <td>6.176466e+07</td>\n",
       "      <td>8.145404</td>\n",
       "      <td>5.094156</td>\n",
       "      <td>205.116213</td>\n",
       "      <td>137.770788</td>\n",
       "      <td>-0.057376</td>\n",
       "      <td>-0.057376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ax_mean      ay_mean     az_mean       gx_mean       gy_mean  \\\n",
       "0 -3210.325581 -1472.639535  769.174419   3888.139535  15000.069767   \n",
       "1 -4266.151163 -1758.790698  433.104651   4868.604651  14022.290698   \n",
       "2 -3777.058140 -2363.441860  496.430233   3838.127907  17846.848837   \n",
       "3 -3545.058140 -1156.709302  618.046512   3811.674419  14340.662791   \n",
       "4 -3078.068966  -793.758621  137.551724  10518.264368   9810.137931   \n",
       "\n",
       "       gz_mean       ax_var       ay_var       az_var        gx_var  ...  \\\n",
       "0 -1508.011628  2625.734377  2141.530712  2579.672441  22376.099388  ...   \n",
       "1  3694.767442  2716.650412  3104.921440  2033.799252  23827.776754  ...   \n",
       "2  2016.662791  2646.756001  2342.910897  2150.277547  25096.946277  ...   \n",
       "3  3557.930233  2507.900301  2258.403467  1908.365970  22559.762748  ...   \n",
       "4 -9929.160920  2518.215706  2126.238452  1811.472957  19047.955661  ...   \n",
       "\n",
       "          a_fft         g_fft         a_psd         g_psd    a_kurt    g_kurt  \\\n",
       "0  34235.187587  34235.187587  8.524912e+09  8.524912e+09  7.929079  2.715360   \n",
       "1   4200.628815   4200.628815  2.855087e+08  2.855087e+08  4.805886  3.387055   \n",
       "2   8077.753674   8077.753674  2.063152e+08  2.063152e+08  3.828190  2.898664   \n",
       "3   5265.867665   5265.867665  1.557855e+08  1.557855e+08  2.039432  3.110605   \n",
       "4   1315.209915   1315.209915  6.176466e+07  6.176466e+07  8.145404  5.094156   \n",
       "\n",
       "      a_skewn     g_skewn  a_entropy  g_entropy  \n",
       "0  193.153135   63.072307  -0.055732  -0.055732  \n",
       "1  116.344046   86.140297  -0.055453  -0.055453  \n",
       "2  113.018318   54.248883  -0.056366  -0.056366  \n",
       "3   30.070979   67.902479  -0.056986  -0.056986  \n",
       "4  205.116213  137.770788  -0.057376  -0.057376  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_file = pd.read_csv(datalist[0])\n",
    "sample_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根據 test_players 分組資料\n",
    "x_train = pd.DataFrame()\n",
    "y_train = pd.DataFrame(columns=target_mask)\n",
    "x_test = pd.DataFrame()\n",
    "y_test = pd.DataFrame(columns=target_mask)\n",
    "\n",
    "for file in datalist:\n",
    "    unique_id = int(Path(file).stem)\n",
    "    row = train_info[train_info['unique_id'] == unique_id]\n",
    "    if row.empty:\n",
    "        continue\n",
    "    player_id = row['player_id'].iloc[0]\n",
    "    data = pd.read_csv(file)\n",
    "    target = row[target_mask]\n",
    "    target_repeated = pd.concat([target] * len(data))\n",
    "    if player_id in train_players:\n",
    "        x_train = pd.concat([x_train, data], ignore_index=True)\n",
    "        y_train = pd.concat([y_train, target_repeated], ignore_index=True)\n",
    "    elif player_id in test_players:\n",
    "        x_test = pd.concat([x_test, data], ignore_index=True)\n",
    "        y_test = pd.concat([y_test, target_repeated], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化特徵\n",
    "scaler = MinMaxScaler()\n",
    "le = LabelEncoder()\n",
    "X_train_scaled = scaler.fit_transform(x_train)\n",
    "X_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "group_size = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Define a simple neural network for binary classification\n",
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Define a neural network for multi-class classification\n",
    "class MultiClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(MultiClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logits = self.model(x)\n",
    "        return logits\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        logits = self.model(x)\n",
    "        return self.softmax(logits)\n",
    "\n",
    "# Function to train binary classification model\n",
    "def train_binary_model(X_train, y_train, X_test, y_test, batch_size=64, epochs=10, lr=0.001):\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.reshape(-1, 1))\n",
    "    X_test_tensor = torch.FloatTensor(X_test)\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Initialize model\n",
    "    input_size = X_train.shape[1]\n",
    "    model = BinaryClassifier(input_size)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}')\n",
    "    \n",
    "    # Make predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predicted = model(X_test_tensor).numpy().flatten()\n",
    "    \n",
    "    # Group predictions\n",
    "    num_groups = len(predicted) // group_size\n",
    "    y_pred = []\n",
    "    for i in range(num_groups):\n",
    "        group_preds = predicted[i*group_size: (i+1)*group_size]\n",
    "        # Use the same logic as your original code\n",
    "        if sum(group_preds[:group_size]) / group_size > 0.5:\n",
    "            y_pred.append(max(group_preds))\n",
    "        else:\n",
    "            y_pred.append(min(group_preds))\n",
    "    \n",
    "    y_test_agg = [y_test[i*group_size] for i in range(num_groups)]\n",
    "    \n",
    "    auc_score = roc_auc_score(y_test_agg, y_pred, average='micro')\n",
    "    print(f'Binary AUC: {auc_score}')\n",
    "    return model, auc_score\n",
    "\n",
    "# Function to train multi-class classification model\n",
    "def train_multi_model(X_train, y_train, X_test, y_test, batch_size=64, epochs=10, lr=0.001):\n",
    "    # Get number of classes\n",
    "    num_classes = len(np.unique(y_train))\n",
    "    \n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    y_train_tensor = torch.LongTensor(y_train)\n",
    "    X_test_tensor = torch.FloatTensor(X_test)\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Initialize model\n",
    "    input_size = X_train.shape[1]\n",
    "    model = MultiClassifier(input_size, num_classes)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}')\n",
    "    \n",
    "    # Make predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(X_test_tensor)\n",
    "        predicted = torch.softmax(logits, dim=1).numpy()\n",
    "    \n",
    "    # Group predictions as in your original code\n",
    "    num_groups = len(predicted) // group_size\n",
    "    y_pred = []\n",
    "    for i in range(num_groups):\n",
    "        group_pred = predicted[i*group_size: (i+1)*group_size]\n",
    "        # Sum probabilities for each class in the group\n",
    "        class_sums = [sum([group_pred[k][j] for k in range(group_size)]) for j in range(num_classes)]\n",
    "        chosen_class = np.argmax(class_sums)\n",
    "        # Get probabilities for the chosen class\n",
    "        candidate_probs = [group_pred[k][chosen_class] for k in range(group_size)]\n",
    "        best_instance = np.argmax(candidate_probs)\n",
    "        y_pred.append(group_pred[best_instance])\n",
    "    \n",
    "    y_test_agg = [y_test[i*group_size] for i in range(num_groups)]\n",
    "    \n",
    "    auc_score = roc_auc_score(y_test_agg, y_pred, average='micro', multi_class='ovr')\n",
    "    print(f'Multi-class AUC: {auc_score}')\n",
    "    return model, auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.41651737363371133\n",
      "Epoch 2/10, Loss: 0.35574488310055463\n",
      "Epoch 3/10, Loss: 0.3026491910718166\n",
      "Epoch 4/10, Loss: 0.2643374332327458\n",
      "Epoch 5/10, Loss: 0.23999136304156785\n",
      "Epoch 6/10, Loss: 0.22434403215459855\n",
      "Epoch 7/10, Loss: 0.2104383984657183\n",
      "Epoch 8/10, Loss: 0.20147640064154584\n",
      "Epoch 9/10, Loss: 0.19488754668350997\n",
      "Epoch 10/10, Loss: 0.1897100304030846\n",
      "Binary AUC: 0.9126506024096386\n",
      "Epoch 1/10, Loss: 0.8333555248592905\n",
      "Epoch 2/10, Loss: 0.6395526257551969\n",
      "Epoch 3/10, Loss: 0.5623715902300186\n",
      "Epoch 4/10, Loss: 0.5132840724386943\n",
      "Epoch 5/10, Loss: 0.4808901316136167\n",
      "Epoch 6/10, Loss: 0.4545907273185489\n",
      "Epoch 7/10, Loss: 0.4253676595843909\n",
      "Epoch 8/10, Loss: 0.41232867811096313\n",
      "Epoch 9/10, Loss: 0.3957994635382744\n",
      "Epoch 10/10, Loss: 0.38115763491872967\n",
      "Multi-class AUC: 0.8323800745772414\n",
      "Epoch 1/10, Loss: 0.830948534077161\n",
      "Epoch 2/10, Loss: 0.7247194632366186\n",
      "Epoch 3/10, Loss: 0.6576969746948196\n",
      "Epoch 4/10, Loss: 0.590321555075943\n",
      "Epoch 5/10, Loss: 0.5444560262801259\n",
      "Epoch 6/10, Loss: 0.5036159948399078\n",
      "Epoch 7/10, Loss: 0.4715209032665468\n",
      "Epoch 8/10, Loss: 0.451438200868428\n",
      "Epoch 9/10, Loss: 0.4306577965276971\n",
      "Epoch 10/10, Loss: 0.41978859162040316\n",
      "Multi-class AUC: 0.6330332567359411\n",
      "Epoch 1/10, Loss: 0.16286545406596076\n",
      "Epoch 2/10, Loss: 0.033601494559867925\n",
      "Epoch 3/10, Loss: 0.02520754498128724\n",
      "Epoch 4/10, Loss: 0.020775315780678122\n",
      "Epoch 5/10, Loss: 0.0177070583567731\n",
      "Epoch 6/10, Loss: 0.015319398540012607\n",
      "Epoch 7/10, Loss: 0.015086305155748391\n",
      "Epoch 8/10, Loss: 0.014899727174564111\n",
      "Epoch 9/10, Loss: 0.014450552624601926\n",
      "Epoch 10/10, Loss: 0.012850762062164376\n",
      "Binary AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# For binary classification (gender)\n",
    "y_train_le_gender = le.fit_transform(y_train['gender'])\n",
    "y_test_le_gender = le.transform(y_test['gender'])\n",
    "binary_model, gender_auc = train_binary_model(X_train_scaled, y_train_le_gender, X_test_scaled, y_test_le_gender)\n",
    "\n",
    "# For multi-class classification (level)\n",
    "y_train_le_level = le.fit_transform(y_train['level'])\n",
    "y_test_le_level = le.transform(y_test['level'])\n",
    "level_model, level_auc = train_multi_model(X_train_scaled, y_train_le_level, X_test_scaled, y_test_le_level)\n",
    "\n",
    "# For multi-class classification (play years)\n",
    "y_train_le_years = le.fit_transform(y_train['play years'])\n",
    "y_test_le_years = le.transform(y_test['play years'])\n",
    "years_model, years_auc = train_multi_model(X_train_scaled, y_train_le_years, X_test_scaled, y_test_le_years)\n",
    "\n",
    "# For binary classification (hold racket handed)\n",
    "y_train_le_hold = le.fit_transform(y_train['hold racket handed'])\n",
    "y_test_le_hold = le.transform(y_test['hold racket handed'])\n",
    "hold_model, hold_auc = train_binary_model(X_train_scaled, y_train_le_hold, X_test_scaled, y_test_le_hold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_binary(X_train, y_train, X_test, y_test):\n",
    "    clf = RandomForestClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    predicted = clf.predict_proba(X_test)\n",
    "    print(predicted.shape) \n",
    "    # 取出正類（index 0）的概率\n",
    "    predicted = [predicted[i][0] for i in range(len(predicted))]\n",
    "\n",
    "    \n",
    "    num_groups = len(predicted) // group_size \n",
    "    if sum(predicted[:group_size]) / group_size > 0.5:\n",
    "        y_pred = [max(predicted[i*group_size: (i+1)*group_size]) for i in range(num_groups)]\n",
    "    else:\n",
    "        y_pred = [min(predicted[i*group_size: (i+1)*group_size]) for i in range(num_groups)]\n",
    "    \n",
    "    y_pred  = [1 - x for x in y_pred]\n",
    "    y_test_agg = [y_test[i*group_size] for i in range(num_groups)]\n",
    "    \n",
    "    auc_score = roc_auc_score(y_test_agg, y_pred, average='micro')\n",
    "    print(auc_score)\n",
    "\n",
    "def model_multiary(X_train, y_train, X_test, y_test):\n",
    "    clf = RandomForestClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    predicted = clf.predict_proba(X_test)\n",
    "    num_groups = len(predicted) // group_size\n",
    "    y_pred = []\n",
    "    for i in range(num_groups):\n",
    "        group_pred = predicted[i*group_size: (i+1)*group_size]\n",
    "        num_classes = len(np.unique(y_train))\n",
    "        # 對每個類別計算該組內的總機率\n",
    "        class_sums = [sum([group_pred[k][j] for k in range(group_size)]) for j in range(num_classes)]\n",
    "        chosen_class = np.argmax(class_sums)\n",
    "        candidate_probs = [group_pred[k][chosen_class] for k in range(group_size)]\n",
    "        best_instance = np.argmax(candidate_probs)\n",
    "        y_pred.append(group_pred[best_instance])\n",
    "    \n",
    "    y_test_agg = [y_test[i*group_size] for i in range(num_groups)]\n",
    "    auc_score = roc_auc_score(y_test_agg, y_pred, average='micro', multi_class='ovr')\n",
    "    print('Multiary AUC:', auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10746, 2)\n",
      "0.7907995618838993\n"
     ]
    }
   ],
   "source": [
    "# 評分：針對各目標進行模型訓練與評分\n",
    "y_train_le_gender = le.fit_transform(y_train['gender'])\n",
    "y_test_le_gender = le.transform(y_test['gender'])\n",
    "model_binary(X_train_scaled, y_train_le_gender, X_test_scaled, y_test_le_gender)\n",
    "\n",
    "# y_train_le_hold = le.fit_transform(y_train['hold racket handed'])\n",
    "# y_test_le_hold = le.transform(y_test['hold racket handed'])\n",
    "# model_binary(X_train_scaled, y_train_le_hold, X_test_scaled, y_test_le_hold)\n",
    "\n",
    "# y_train_le_years = le.fit_transform(y_train['play years'])\n",
    "# y_test_le_years = le.transform(y_test['play years'])\n",
    "# model_multiary(X_train_scaled, y_train_le_years, X_test_scaled, y_test_le_years)\n",
    "\n",
    "# y_train_le_level = le.fit_transform(y_train['level'])\n",
    "# y_test_le_level = le.transform(y_test['level'])\n",
    "# model_multiary(X_train_scaled, y_train_le_level, X_test_scaled, y_test_le_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2], dtype=object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test['gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(le.fit_transform(y_test['level']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aicup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
